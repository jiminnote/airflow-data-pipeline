from airflow import DAG
from airflow.providers.http.operators.http import HttpOperator
from airflow.providers.standard.operators.python import PythonOperator
from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator
from datetime import datetime, timedelta
import json

API_KEY = '5f89bcebb90262564e8d1193a28933e0'
# ìˆ˜ì§‘í•  ë„ì‹œ ëª©ë¡ (ê³µë°± ì œê±°!)
CITIES = [
    {'name': 'Seoul', 'query': 'Seoul'},
    {'name': 'Tokyo', 'query': 'Tokyo'},
    {'name': 'New_York', 'query': 'New York'},  # â† Task IDìš© / API ì¿¼ë¦¬ìš© ë¶„ë¦¬
    {'name': 'London', 'query': 'London'},
    {'name': 'Paris', 'query': 'Paris'}
]

def extract_weather_data(city_name, city_query, **context):
    """API ì‘ë‹µì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ"""
    ti = context['ti']
    response = ti.xcom_pull(task_ids=f'fetch_weather_{city_name}')
    
    if not response:
        print(f"âŒ {city_query} ë°ì´í„° ì—†ìŒ")
        return None
    
    data = json.loads(response)
    
    # í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
    weather_info = {
        'city': city_query,  # í‘œì‹œìš©ì€ ì›ëž˜ ì´ë¦„
        'temperature': data['main']['temp'],
        'feels_like': data['main']['feels_like'],
        'humidity': data['main']['humidity'],
        'description': data['weather'][0]['description'],
        'wind_speed': data['wind']['speed'],
        'collected_at': datetime.now().isoformat()
    }
    
    print(f"ðŸ“Š {city_query}: {weather_info['temperature']}Â°C, {weather_info['description']}")
    
    return weather_info

def save_all_weather_data(**context):
    """ëª¨ë“  ë„ì‹œì˜ ë‚ ì”¨ ë°ì´í„°ë¥¼ DBì— ì €ìž¥"""
    ti = context['ti']
    
    from airflow.providers.postgres.hooks.postgres import PostgresHook
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    saved_count = 0
    
    for city in CITIES:
        weather_data = ti.xcom_pull(task_ids=f'extract_{city["name"]}')
        
        if not weather_data:
            continue
        
        try:
            hook.run("""
                INSERT INTO weather_data 
                (city, temperature, feels_like, humidity, description, wind_speed, collected_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """, parameters=(
                weather_data['city'],
                weather_data['temperature'],
                weather_data['feels_like'],
                weather_data['humidity'],
                weather_data['description'],
                weather_data['wind_speed'],
                weather_data['collected_at']
            ))
            
            saved_count += 1
            print(f"âœ… {city['query']} ë°ì´í„° ì €ìž¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ {city['query']} ì €ìž¥ ì‹¤íŒ¨: {e}")
    
    print(f"\nðŸ“Š ì´ {saved_count}/{len(CITIES)} ë„ì‹œ ë°ì´í„° ì €ìž¥ë¨")

def generate_daily_report(**context):
    """ì¼ì¼ ë‚ ì”¨ ë¦¬í¬íŠ¸ ìƒì„±"""
    from airflow.providers.postgres.hooks.postgres import PostgresHook
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    # ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë°ì´í„° ì¡°íšŒ
    records = hook.get_records("""
        SELECT city, temperature, description, collected_at
        FROM weather_data
        WHERE DATE(collected_at) = CURRENT_DATE
        ORDER BY temperature DESC
    """)
    
    if not records:
        print("âš ï¸ ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("\n" + "="*50)
    print(f"ðŸ“‹ ì¼ì¼ ë‚ ì”¨ ë¦¬í¬íŠ¸ - {datetime.now().strftime('%Y-%m-%d')}")
    print("="*50)
    
    for idx, record in enumerate(records, 1):
        city, temp, desc, collected = record
        print(f"{idx}. {city:15s} {temp:6.1f}Â°C  {desc}")
    
    print("="*50)
    
    # í†µê³„ ì •ë³´
    temps = [r[1] for r in records]
    print(f"\nðŸ“Š í†µê³„:")
    print(f"   ìµœê³  ê¸°ì˜¨: {max(temps):.1f}Â°C ({records[0][0]})")
    print(f"   ìµœì € ê¸°ì˜¨: {min(temps):.1f}Â°C ({records[-1][0]})")
    print(f"   í‰ê·  ê¸°ì˜¨: {sum(temps)/len(temps):.1f}Â°C")

default_args = {
    'owner': 'airflow',
    'retries': 2,
    'retry_delay': timedelta(minutes=1),
}

with DAG(
    dag_id='weather_pipeline',
    default_args=default_args,
    start_date=datetime(2024, 1, 1),
    schedule=None,
    catchup=False,
    tags=['production', 'weather']
) as dag:
    
    # Task 1: í…Œì´ë¸” ìƒì„±
    create_table = SQLExecuteQueryOperator(
        task_id='create_table',
        conn_id='postgres_default',
        sql="""
            CREATE TABLE IF NOT EXISTS weather_data (
                id SERIAL PRIMARY KEY,
                city VARCHAR(50),
                temperature FLOAT,
                feels_like FLOAT,
                humidity INT,
                description VARCHAR(100),
                wind_speed FLOAT,
                collected_at TIMESTAMP
            )
        """
    )
    
    # Task 2-6: ê° ë„ì‹œë³„ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘
    fetch_tasks = []
    extract_tasks = []
    
    for city in CITIES:
        # API í˜¸ì¶œ
        fetch = HttpOperator(
            task_id=f'fetch_weather_{city["name"]}',
            http_conn_id='weather_api',
            endpoint=f'/data/2.5/weather?q={city["query"]}&appid={API_KEY}&units=metric',  # â† demoë¥¼ {API_KEY}ë¡œ ë³€ê²½!
            method='GET',
            response_filter=lambda response: response.text,
            log_response=True
        )
        
        # ë°ì´í„° ì¶”ì¶œ
        extract = PythonOperator(
            task_id=f'extract_{city["name"]}',
            python_callable=extract_weather_data,
            op_kwargs={'city_name': city['name'], 'city_query': city['query']}
        )
        
        fetch >> extract
        
        fetch_tasks.append(fetch)
        extract_tasks.append(extract)
    
    # Task 7: ëª¨ë“  ë°ì´í„° DB ì €ìž¥
    save_data = PythonOperator(
        task_id='save_to_database',
        python_callable=save_all_weather_data
    )
    
    # Task 8: ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±
    report = PythonOperator(
        task_id='generate_report',
        python_callable=generate_daily_report
    )
    
    # ì˜ì¡´ì„± ì„¤ì •
    create_table >> fetch_tasks
    extract_tasks >> save_data >> report