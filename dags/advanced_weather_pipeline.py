from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.bash import BashOperator
from airflow.utils.task_group import TaskGroup
from airflow.models import Variable
from datetime import datetime, timedelta
import json

OPENWEATHER_API_KEY = Variable.get("openweather_api_key")
CITIES = ['Seoul', 'Tokyo', 'Beijing', 'Bangkok', 'Singapore', 'New York']

def extract_weather_data(ti, city: str):
    """1. ë‚ ì”¨ ë°ì´í„° ì¶”ì¶œ"""
    print(f"ğŸŒ Extracting weather for {city}...")
    
    api = WeatherAPI(OPENWEATHER_API_KEY)
    raw_data = api.get_weather(city)
    
    if raw_data:
        ti.xcom_push(key=f'raw_{city}', value=raw_data)
        print(f"âœ… Successfully extracted {city}")
        return raw_data
    else:
        raise Exception(f"Failed to extract weather for {city}")
    
def validate_weather_data(ti, city: str):
    """2. ë°ì´í„° ê²€ì¦"""
    print(f"ğŸ” Validating weather data for {city}...")
    
    raw_data = ti.xcom_pull(key=f'raw_{city}',   task_ids=f'city_group_{city}.extract_{city}')
    
    validator = WeatherValidator()
    is_valid, message = validator.validate(raw_data, city)
    
    if is_valid:
        print(f"âœ… Valid data for {city}")
        ti.xcom_push(key=f'valid_{city}', value=True)
        return True
    else:
        print(f"âŒ Invalid data for {city}: {message}")
        raise ValueError(f"Validation failed for {city}: {message}")

def transform_weather_data(ti, city: str):
    """3. ë°ì´í„° ë³€í™˜"""
    print(f"ğŸ”„ Transforming weather data for {city}...")
    
    raw_data = ti.xcom_pull(key=f'raw_{city}', task_ids=f'city_group_{city}.extract_{city}')
    
    processor = WeatherProcessor()
    clean_data = processor.transform_data(raw_data)
    
    ti.xcom_push(key=f'clean_{city}', value=clean_data)
    print(f"âœ… Transformed {city}: {clean_data['weather_category']}")
    
    return clean_data

def categorize_weather(ti, city: str):
    """4. ë‚ ì”¨ ìƒíƒœë³„ ë¶„ê¸°"""
    clean_data = ti.xcom_pull(
        key=f'clean_{city}',
        task_ids=f'city_group_{city}.transform_{city}'
    )
    
    category = clean_data['weather_category']
    print(f"ğŸŒ¤ï¸ {city} weather category: {category}")
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‹¤ë¥¸ task ë°˜í™˜
    task_mapping = {
        'sunny': f'city_group_{city}.process_sunny_{city}',
        'rainy': f'city_group_{city}.process_rainy_{city}',
        'snowy': f'city_group_{city}.process_snowy_{city}',
        'cloudy': f'city_group_{city}.process_cloudy_{city}',
        'other': f'city_group_{city}.process_other_{city}'
    }

    return task_mapping.get(category, f'city_group_{city}.process_other_{city}')

def process_sunny_weather(city: str):
    """ë§‘ì€ ë‚ ì”¨ ì²˜ë¦¬"""
    print(f"â˜€ï¸ {city}: Sunny weather processing")
    print(f"   - UV index check recommended")
    print(f"   - Outdoor activity suitable")
    return f"{city}_sunny_processed"

def process_rainy_weather(city: str):
    """ë¹„ ì˜¤ëŠ” ë‚ ì”¨ ì²˜ë¦¬"""
    print(f"ğŸŒ§ï¸ {city}: Rainy weather processing")
    print(f"   - Umbrella alert sent")
    print(f"   - Flood warning check")
    return f"{city}_rainy_processed"

def process_snowy_weather(city: str):
    """ëˆˆ ì˜¤ëŠ” ë‚ ì”¨ ì²˜ë¦¬"""
    print(f"â„ï¸ {city}: Snowy weather processing")
    print(f"   - Traffic delay warning")
    print(f"   - Cold weather alert")
    return f"{city}_snowy_processed"

def process_cloudy_weather(city: str):
    """íë¦° ë‚ ì”¨ ì²˜ë¦¬"""
    print(f"â˜ï¸ {city}: Cloudy weather processing")
    print(f"   - Standard weather conditions")
    return f"{city}_cloudy_processed"

def process_other_weather(city: str):
    """ê¸°íƒ€ ë‚ ì”¨ ì²˜ë¦¬"""
    print(f"ğŸŒ«ï¸ {city}: Other weather processing")
    return f"{city}_other_processed"

def load_to_database(ti, ds, city: str):
    """5. ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ (ì‹œë®¬ë ˆì´ì…˜)"""
    print(f"ğŸ’¾ Loading {city} data to database...")
    
    clean_data = ti.xcom_pull(
        key=f'clean_{city}',
        task_ids=f'city_group_{city}.transform_{city}'
    )
    
    # ì‹¤ì œë¡œëŠ” PostgresHook ì‚¬ìš©
    # from airflow.providers.postgres.hooks.postgres import PostgresHook
    # pg_hook = PostgresHook(postgres_conn_id='postgres_default')
    # pg_hook.run(sql=..., parameters=...)
    
    print(f"âœ… Saved to DB: {clean_data['city']} - {clean_data['temperature']}Â°C")
    print(f"   Date: {ds}")
    
    return f"{city}_loaded"

def aggregate_all_cities(ti):
    """6. ëª¨ë“  ë„ì‹œ ë°ì´í„° ì§‘ê³„"""
    print("ğŸ“Š Aggregating all city data...")
    
    all_data = []
    for city in CITIES:
        try:
            data = ti.xcom_pull(
                key=f'clean_{city}',
                task_ids=f'city_group_{city}.transform_{city}'
            )
            if data:
                all_data.append(data)
        except Exception as e:
            print(f"âš ï¸ Could not aggregate {city}: {e}")
    
    # í†µê³„ ê³„ì‚°
    if all_data:
        avg_temp = sum(d['temperature'] for d in all_data) / len(all_data)
        avg_humidity = sum(d['humidity'] for d in all_data) / len(all_data)
        
        print(f"ğŸ“ˆ Statistics:")
        print(f"   - Cities processed: {len(all_data)}/{len(CITIES)}")
        print(f"   - Average temperature: {avg_temp:.1f}Â°C")
        print(f"   - Average humidity: {avg_humidity:.1f}%")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë„ì‹œ ìˆ˜
        categories = {}
        for d in all_data:
            cat = d['weather_category']
            categories[cat] = categories.get(cat, 0) + 1
        
        print(f"   - Weather distribution: {categories}")
        
        ti.xcom_push(key='summary', value={
            'total_cities': len(all_data),
            'avg_temp': avg_temp,
            'avg_humidity': avg_humidity,
            'categories': categories
        })
    
    return all_data

def send_summary_report(ti, ds):
    """7. ìš”ì•½ ë¦¬í¬íŠ¸ ë°œì†¡"""
    print("ğŸ“§ Sending summary report...")
    
    summary = ti.xcom_pull(key='summary', task_ids='aggregate')
    
    if summary:
        print(f"""
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸŒ Weather Pipeline Summary
        Date: {ds}
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        âœ… Cities Processed: {summary['total_cities']}
        ğŸŒ¡ï¸  Avg Temperature: {summary['avg_temp']:.1f}Â°C
        ğŸ’§ Avg Humidity: {summary['avg_humidity']:.1f}%
        
        Weather Distribution:
        {json.dumps(summary['categories'], indent=2)}
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
    
    # ì‹¤ì œë¡œëŠ” EmailOperator ë˜ëŠ” SlackWebhookOperator ì‚¬ìš©
    return "Report sent"

def failure_callback(context):
    """ì‹¤íŒ¨ ì‹œ ì½œë°±"""
    task_id = context['task_instance'].task_id
    dag_id = context['task_instance'].dag_id
    execution_date = context['execution_date']
    exception = context.get('exception')
    
    print(f"""
    âŒ Task Failed!
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    DAG: {dag_id}
    Task: {task_id}
    Execution Date: {execution_date}
    Error: {exception}
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ”” Alert sent to Slack/Email
    """)
    
    # ì‹¤ì œë¡œëŠ” SlackWebhookOperator ì‚¬ìš©
    # slack_alert = SlackWebhookOperator(...)

# ========== DAG ì •ì˜ ==========

default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'email': ['alerts@company.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,  # 3ë²ˆ ì¬ì‹œë„
    'retry_delay': timedelta(minutes=2),
    'retry_exponential_backoff': True,
    'max_retry_delay': timedelta(minutes=10),
    'on_failure_callback': failure_callback,  # ì‹¤íŒ¨ ì‹œ ì½œë°±
}

with DAG(
    dag_id='advanced_weather_pipeline',
    default_args=default_args,
    description='Advanced weather data pipeline with validation and branching',
    schedule_interval='0 */3 * * *',  # 3ì‹œê°„ë§ˆë‹¤
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['production', 'weather', 'etl'],
    max_active_runs=1,
) as dag:
    
    # ì‹œì‘
    start = BashOperator(
        task_id='start',
        bash_command='echo "ğŸš€ Weather pipeline started at $(date)"'
    )
    
    # ë„ì‹œë³„ TaskGroup ìƒì„±
    city_groups = []
    
    for city in CITIES:
        with TaskGroup(f'city_group_{city}', tooltip=f'Process {city} weather') as city_group:
            
            # 1. ì¶”ì¶œ
            extract = PythonOperator(
                task_id=f'extract_{city}',
                python_callable=extract_weather_data,
                op_kwargs={'city': city},
            )
            
            # 2. ê²€ì¦
            validate = PythonOperator(
                task_id=f'validate_{city}',
                python_callable=validate_weather_data,
                op_kwargs={'city': city},
            )
            
            # 3. ë³€í™˜
            transform = PythonOperator(
                task_id=f'transform_{city}',
                python_callable=transform_weather_data,
                op_kwargs={'city': city},
            )
            
            # 4. ë‚ ì”¨ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ê¸°
            branch = BranchPythonOperator(
                task_id=f'branch_{city}',
                python_callable=categorize_weather,
                op_kwargs={'city': city},
            )
            
            # 5. ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬ Taskë“¤
            sunny = PythonOperator(
                task_id=f'process_sunny_{city}',
                python_callable=process_sunny_weather,
                op_kwargs={'city': city},
            )
            
            rainy = PythonOperator(
                task_id=f'process_rainy_{city}',
                python_callable=process_rainy_weather,
                op_kwargs={'city': city},
            )
            
            snowy = PythonOperator(
                task_id=f'process_snowy_{city}',
                python_callable=process_snowy_weather,
                op_kwargs={'city': city},
            )
            
            cloudy = PythonOperator(
                task_id=f'process_cloudy_{city}',
                python_callable=process_cloudy_weather,
                op_kwargs={'city': city},
            )
            
            other = PythonOperator(
                task_id=f'process_other_{city}',
                python_callable=process_other_weather,
                op_kwargs={'city': city},
            )
            
            # 6. ë°ì´í„° ì ì¬
            load = PythonOperator(
                task_id=f'load_{city}',
                python_callable=load_to_database,
                op_kwargs={'city': city},
                trigger_rule='none_failed_min_one_success',  # Branch ì´í›„
            )
            
            # TaskGroup ë‚´ë¶€ ì˜ì¡´ì„±
            extract >> validate >> transform >> branch
            branch >> [sunny, rainy, snowy, cloudy, other] >> load
        
        city_groups.append(city_group)
    
    # ì§‘ê³„
    aggregate = PythonOperator(
        task_id='aggregate',
        python_callable=aggregate_all_cities,
        trigger_rule='none_failed_min_one_success',  # ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ì§‘ê³„
    )
    
    # ë¦¬í¬íŠ¸
    report = PythonOperator(
        task_id='send_report',
        python_callable=send_summary_report,
    )
    
    # ì¢…ë£Œ
    end = BashOperator(
        task_id='end',
        bash_command='echo "âœ… Weather pipeline completed at $(date)"',
        trigger_rule='none_failed_min_one_success',
    )
    
    # ========== ì „ì²´ ì˜ì¡´ì„± ==========
    start >> city_groups >> aggregate >> report >> end
